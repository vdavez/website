---
slug-title: cycle-times
date: 2020-01-14T08:41:37-06:00
draft: false
title: "Cycle Times"
subtitle: Little's Law in Real Life
---
Here's a Little formula:  

> average number of things in queue = average processing rate x average cycle time

No, that's *actually* [Little's Law](https://en.wikipedia.org/wiki/Little's_law), named after a MIT professor named John Little. It's often written as `(l = Î»w)`.

I first learned about Little's Law at 18F because it's a major feature of [agile methodology](https://en.wikipedia.org/wiki/Agile_software_development). Specifically, agile practitioners have recognized that if you're focused on optimizing "cycle time," and you can't force software engineers to work *faster*, the lever available to you is to reduce the number of things in queue. So, agile practitioners focus on managing *Works in Progress* or "WIP" and establish "WIP limits" (pronounced "whip limits") as a means of controlling and improving cycle-time performance.

 But Little's Law has applications far beyond software development. Managing cycle time is critical to everything from highway tolling, retail-customer transactions, and more. It turns out that, perhaps, based on recent research, cycle time may also be [empirically correlated with success across science, startups, and security](https://www.nature.com/articles/s41586-019-1725-y). As [one of the researchers explained](https://hbr.org/ideacast/2019/12/the-tipping-point-between-failure-and-success):

 > But when you look at a success group, with each failure, their efficiency systematically improves the inter-event time between two consecutive attempts systematically decreases. So this means they start to fail faster and faster eventually to succeed.

 In other words, as the cycle time between _attempts_ goes down, success increases. This finding certainly could have broad implications about how people and organizations should approach their work. Perhaps a Little goes a long way. :rimshot:
